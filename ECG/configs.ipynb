{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2cf518-eed8-4aa5-b9e9-bd9021a48c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hparams_class(dataset_name):\n",
    "    \"\"\"Return the algorithm class with the given name.\"\"\"\n",
    "    if dataset_name not in globals():\n",
    "        raise NotImplementedError(\"Algorithm not found: {}\".format(dataset_name))\n",
    "    return globals()[dataset_name]\n",
    "\n",
    "\n",
    "class supervised():\n",
    "    def __init__(self):\n",
    "        super(supervised, self).__init__()\n",
    "        self.train_params = {\n",
    "            'num_epochs': 60,\n",
    "            'batch_size': 128,\n",
    "            'weight_decay': 1e-4,\n",
    "            'learning_rate': 1e-3,\n",
    "            'feature_dim': 1*128\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110be6e9-9819-4ffd-b457-a4829be18cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_class(dataset_name):\n",
    "    \"\"\"Return the algorithm class with the given name.\"\"\"\n",
    "    if dataset_name not in globals():\n",
    "        raise NotImplementedError(\"Dataset not found: {}\".format(dataset_name))\n",
    "    return globals()[dataset_name]\n",
    "\n",
    "\n",
    "class mit():\n",
    "    def __init__(self):\n",
    "        super(mit, self).__init__()\n",
    "        # data parameters\n",
    "        self.num_classes = 5\n",
    "        self.class_names = ['N', 'S', 'V', 'F', 'Q']\n",
    "        self.sequence_len = 186\n",
    "\n",
    "        # model configs\n",
    "        self.input_channels = 1\n",
    "        self.kernel_size = 8\n",
    "        self.stride = 1\n",
    "        self.dropout = 0.2\n",
    "\n",
    "        # features\n",
    "        self.mid_channels = 32\n",
    "        self.final_out_channels = 128\n",
    "\n",
    "        # Transformer\n",
    "        self.trans_dim = 25\n",
    "        self.num_heads = 5\n",
    "\n",
    "\n",
    "class incart():\n",
    "    def __init__(self):\n",
    "        super(incart, self).__init__()\n",
    "        # data parameters\n",
    "        self.num_classes = 2\n",
    "        self.class_names = ['normal', 'abnormal']\n",
    "        # self.class_names = ['N', 'S', 'V', 'F', 'Q']\n",
    "        self.sequence_len = 186\n",
    "\n",
    "        # model configs\n",
    "        self.input_channels = 1  # 15\n",
    "        self.kernel_size = 8\n",
    "        self.stride = 1\n",
    "        self.dropout = 0.2\n",
    "\n",
    "        # features\n",
    "        self.mid_channels = 32\n",
    "        self.final_out_channels = 128\n",
    "\n",
    "        # Transformer\n",
    "        self.trans_dim = 25\n",
    "        self.num_heads = 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
