{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203c8a43-0ef6-4478-b2b1-b826d55f8841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "class ACA(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channel,stride, downsample=None,  ratio=4):\n",
    "        super(ACA, self).__init__()\n",
    "        ratio=4\n",
    "        hide_channel = in_channel // ratio\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)  # 将2d改为1d\n",
    "        self.conv1 = nn.Conv1d(in_channel, hide_channel, kernel_size=1, bias=False)  # 将2d改为1d\n",
    "        self.softmax = nn.Softmax(dim=1)  # softmax的维度保持不变\n",
    "        self.A0 = torch.eye(hide_channel).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.A2 = nn.Parameter(torch.zeros(hide_channel, hide_channel), requires_grad=True)\n",
    "        init.constant_(self.A2, 1e-6)\n",
    "        self.conv2 = nn.Conv1d(1, 1, kernel_size=1, bias=False)  # 保持不变\n",
    "        self.conv3 = nn.Conv1d(1, 1, kernel_size=1, bias=False)  # 保持不变\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv4 = nn.Conv1d(hide_channel, in_channel, kernel_size=1, bias=False)  # 将2d改为1d\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.bn = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, L)\n",
    "        y = self.avg_pool(x)  # (B, C, 1)\n",
    "        y1 = self.conv1(y)  # (B, hide_channel, 1)\n",
    "        y2 = self.conv1(y)\n",
    "        y = y1 + y2\n",
    "        y = torch.mean(torch.stack([y1, y2],2), 2)\n",
    "        y = self.relu(self.bn(y))\n",
    "\n",
    "        \n",
    "        B, C, _ = y.size()\n",
    "        y = y.transpose(1, 2)  # (B, 1, C/r) \n",
    "        # print(y.size())\n",
    "        # A1 = self.softmax(self.conv2(y))  # ( B，1，C/r)\n",
    "        \n",
    "\n",
    "        \n",
    "        A1 = self.softmax(y)\n",
    "        # A1 = A1.unsqueeze(0)  # (C, B, 1)\n",
    "        A = (self.A0 * A1) + self.A2  # (C, B)\n",
    "        y = torch.matmul(y, A)  # (C, B) * (C, B) -> (C, B)\n",
    "        y = self.relu(self.conv3(y))  # (B,1,C/r)\n",
    "        # print(y.size())\n",
    "        y = y.transpose(1, 2)  # (B，1，C/r) -> (B, C, 1)\n",
    "        y = self.sigmoid(self.conv4(y))  # (B, C, 1)\n",
    "\n",
    "        return x * y  # (B, C, L) * (B, C, 1) -> (B, C, L)\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, configs, hparams):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        filter_sizes = [5, 9, 11,3]\n",
    "        self.conv4 = nn.Conv1d(configs.input_channels, configs.mid_channels, kernel_size=filter_sizes[3],\n",
    "                               stride=configs.stride, bias=False, padding=(filter_sizes[3] // 2))\n",
    "        self.conv1 = nn.Conv1d(configs.input_channels, configs.mid_channels, kernel_size=filter_sizes[0],\n",
    "                               stride=configs.stride, bias=False, padding=(filter_sizes[0] // 2))\n",
    "        self.conv2 = nn.Conv1d(configs.input_channels, configs.mid_channels, kernel_size=filter_sizes[1],\n",
    "                               stride=configs.stride, bias=False, padding=(filter_sizes[1] // 2))\n",
    "        self.conv3 = nn.Conv1d(configs.input_channels, configs.mid_channels, kernel_size=filter_sizes[2],\n",
    "                               stride=configs.stride, bias=False, padding=(filter_sizes[2] // 2))\n",
    "        self.bn = nn.BatchNorm1d(configs.mid_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.mp = nn.MaxPool1d(kernel_size=2, stride=2, padding=1)\n",
    "        self.do = nn.Dropout(configs.dropout)\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv1d(configs.mid_channels, configs.mid_channels * 2, kernel_size=8, stride=1, bias=False, padding=4),\n",
    "            nn.BatchNorm1d(configs.mid_channels * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv1d(configs.mid_channels * 2, configs.final_out_channels, kernel_size=8, stride=1, bias=False,\n",
    "                      padding=4),\n",
    "            nn.BatchNorm1d(configs.final_out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2, padding=1),\n",
    "        )\n",
    "        \n",
    "        self.inplanes = 128\n",
    "        # self.cbam = self._make_layer(ACA, 128, 1)\n",
    "        self.aca = ACA(128,1)\n",
    "\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=configs.trans_dim, nhead=configs.num_heads, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=3)\n",
    "        \n",
    "        self.aap = nn.AdaptiveAvgPool1d(1)\n",
    "        self.clf = nn.Linear(hparams[\"feature_dim\"], configs.num_classes)\n",
    "    def forward(self, x_in):\n",
    "        # print(x_in.shape)\n",
    "\n",
    "        # Multi-scale Convolutions\n",
    "        x1 = self.conv1(x_in)\n",
    "        x2 = self.conv2(x_in)\n",
    "        x3 = self.conv3(x_in)\n",
    "        x4 = self.conv4(x_in)\n",
    "        x_concat = torch.mean(torch.stack([x1, x2, x3,x4],2), 2)\n",
    "        x_concat = self.do(self.mp(self.relu(self.bn(x_concat))))\n",
    "\n",
    "        x = self.conv_block2(x_concat)\n",
    "        x = self.conv_block3(x)\n",
    "\n",
    "        # ACA module\n",
    "        x = self.aca(x)\n",
    "        \n",
    "        # Bi-directional Transformer\n",
    "        x1 = self.transformer_encoder(x)\n",
    "        x2 = self.transformer_encoder(torch.flip(x,[2]))\n",
    "\n",
    "\n",
    "        x = x1+x2\n",
    "\n",
    "        x = self.aap(x)\n",
    "        x_flat = x.reshape(x.shape[0], -1)\n",
    "        x_out = self.clf(x_flat)\n",
    "        return x_out\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
