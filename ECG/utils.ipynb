{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2172f0b-4365-437f-807c-7327855cb98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shutil import copy\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes, cmap_name='Blues'):\n",
    "    \"\"\"\n",
    "    绘制混淆矩阵的函数。\n",
    "\n",
    "    参数:\n",
    "    y_true -- 真实标签列表。\n",
    "    y_pred -- 预测标签列表。\n",
    "    classes -- 类别标签列表。\n",
    "    cmap_name -- 颜色映射名称，默认为'Blues'。\n",
    "    \"\"\"\n",
    "    # 计算混淆矩阵\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # 绘制混淆矩阵\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap=cmap_name, cbar=False, xticklabels=classes, yticklabels=classes)\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def compute_class_frequencies(targets, num_classes):\n",
    "    # 计算每个类别的样本数量\n",
    "    class_counts = torch.bincount(targets, minlength=num_classes)\n",
    "    \n",
    "    # 防止除零错误，计算每个类别的频率\n",
    "    class_freq = 1.0 / (class_counts + 1e-6)\n",
    "    \n",
    "    # 归一化类别频率\n",
    "    class_freq = class_freq / torch.sum(class_freq)\n",
    "    \n",
    "    return class_freq\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def fix_randomness(SEED):\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def _logger(logger_name, level=logging.DEBUG):\n",
    "    \"\"\"\n",
    "    Method to return a custom logger with the given name and level\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(logger_name)\n",
    "    logger.setLevel(level)\n",
    "    format_string = \"%(message)s\"\n",
    "    log_format = logging.Formatter(format_string)\n",
    "    # Creating and adding the console handler\n",
    "    console_handler = logging.StreamHandler(sys.stdout)\n",
    "    console_handler.setFormatter(log_format)\n",
    "    logger.addHandler(console_handler)\n",
    "    # Creating and adding the file handler\n",
    "    file_handler = logging.FileHandler(logger_name, mode='a')\n",
    "    file_handler.setFormatter(log_format)\n",
    "    logger.addHandler(file_handler)\n",
    "    return logger\n",
    "\n",
    "\n",
    "def starting_logs(data_type, exp_log_dir, seed_id):\n",
    "    log_dir = os.path.join(exp_log_dir, \"_seed_\" + str(seed_id))\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    log_file_name = os.path.join(log_dir, f\"logs_{datetime.datetime.now().strftime('%d_%m_%Y_%H_%M_%S')}.log\")\n",
    "    logger = _logger(log_file_name)\n",
    "    logger.debug(\"=\" * 45)\n",
    "    logger.debug(f'Dataset: {data_type}')\n",
    "    logger.debug(\"=\" * 45)\n",
    "    logger.debug(f'Seed: {seed_id}')\n",
    "    logger.debug(\"=\" * 45)\n",
    "    return logger, log_dir\n",
    "\n",
    "\n",
    "def save_checkpoint(exp_log_dir, model, dataset, dataset_configs, hparams, status):\n",
    "    save_dict = {\n",
    "        \"dataset\": dataset,\n",
    "        \"configs\": dataset_configs.__dict__,\n",
    "        \"hparams\": dict(hparams),\n",
    "        \"model\": model.state_dict()\n",
    "    }\n",
    "    # save classification report\n",
    "    save_path = os.path.join(exp_log_dir, f\"checkpoint_{status}.pt\")\n",
    "\n",
    "    torch.save(save_dict, save_path)\n",
    "\n",
    "\n",
    "def _calc_metrics(pred_labels, true_labels, classes_names):\n",
    "    pred_labels = np.array(pred_labels).astype(int)\n",
    "    true_labels = np.array(true_labels).astype(int)\n",
    "\n",
    "    r = classification_report(true_labels, pred_labels, target_names=classes_names, digits=6, output_dict=True)\n",
    "    accuracy = accuracy_score(true_labels, pred_labels)\n",
    "\n",
    "    return accuracy * 100, r[\"macro avg\"][\"f1-score\"] * 100\n",
    "\n",
    "\n",
    "def _save_metrics(pred_labels, true_labels, log_dir, status):\n",
    "    pred_labels = np.array(pred_labels).astype(int)\n",
    "    true_labels = np.array(true_labels).astype(int)\n",
    "\n",
    "    r = classification_report(true_labels, pred_labels, digits=6, output_dict=True)\n",
    "\n",
    "    df = pd.DataFrame(r)\n",
    "    accuracy = accuracy_score(true_labels, pred_labels)\n",
    "    df[\"accuracy\"] = accuracy\n",
    "    df = df * 100\n",
    "\n",
    "    # save classification report\n",
    "    file_name = f\"classification_report_{status}.xlsx\"\n",
    "    report_Save_path = os.path.join(log_dir, file_name)\n",
    "    df.to_excel(report_Save_path)\n",
    "\n",
    "\n",
    "import collections\n",
    "\n",
    "\n",
    "def to_device(input, device):\n",
    "    if torch.is_tensor(input):\n",
    "        return input.to(device=device)\n",
    "    elif isinstance(input, str):\n",
    "        return input\n",
    "    elif isinstance(input, collections.abc.Mapping):\n",
    "        return {k: to_device(sample, device=device) for k, sample in input.items()}\n",
    "    elif isinstance(input, collections.abc.Sequence):\n",
    "        return [to_device(sample, device=device) for sample in input]\n",
    "    else:\n",
    "        raise TypeError(\"Input must contain tensor, dict or list, found {type(input)}\")\n",
    "\n",
    "\n",
    "\n",
    "# 指数平滑函数\n",
    "def exponential_smoothing(data, alpha):\n",
    "    smoothed = np.zeros_like(data)\n",
    "    smoothed[0] = data[0]\n",
    "    for i in range(1, len(data)):\n",
    "        smoothed[i] = alpha * data[i] + (1 - alpha) * smoothed[i - 1]\n",
    "    return smoothed\n",
    "\n",
    "def plot_metrics(train_losses, val_losses, train_accuracies, val_accuracies):\n",
    "    \n",
    "    train_losses = [loss.cpu().numpy() if isinstance(loss, torch.Tensor) else loss for loss in train_losses]\n",
    "    val_losses = [loss.cpu().numpy() if isinstance(loss, torch.Tensor) else loss for loss in val_losses]\n",
    "    train_accuracies = [acc.cpu().numpy() if isinstance(acc, torch.Tensor) else acc for acc in train_accuracies]\n",
    "    val_accuracies = [acc.cpu().numpy() if isinstance(acc, torch.Tensor) else acc for acc in val_accuracies]\n",
    "    \n",
    "\n",
    "    # 平滑系数\n",
    "    alpha = 0.25\n",
    "    \n",
    "    # 对训练损失、验证损失、训练准确度和验证准确度进行平滑\n",
    "    smoothed_train_losses = exponential_smoothing(train_losses, alpha)\n",
    "    smoothed_val_losses = exponential_smoothing(val_losses, alpha)\n",
    "    smoothed_train_accuracies = exponential_smoothing(train_accuracies, alpha)\n",
    "    smoothed_val_accuracies = exponential_smoothing(val_accuracies, alpha)\n",
    "    \n",
    "    smoothed_train_losses = exponential_smoothing(smoothed_train_losses, 0.5)\n",
    "    smoothed_val_losses = exponential_smoothing(smoothed_val_losses, 0.5)\n",
    "    smoothed_train_accuracies = exponential_smoothing(smoothed_train_accuracies, 0.5)\n",
    "    smoothed_val_accuracies = exponential_smoothing(smoothed_val_accuracies, 0.5)\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # 第一个子图：平滑后的损失曲线\n",
    "    plt.subplot(1, 2, 1)  # 1行2列的第1个\n",
    "    plt.plot(smoothed_train_losses, label='Train Loss')\n",
    "    plt.plot(smoothed_val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(' Loss Curves')\n",
    "    plt.legend()\n",
    "    \n",
    "    # 第二个子图：平滑后的准确度曲线\n",
    "    plt.subplot(1, 2, 2)  # 1行2列的第2个\n",
    "    plt.plot(smoothed_train_accuracies, label='Train Accuracy')\n",
    "    plt.plot(smoothed_val_accuracies, label='Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(' Accuracy Curves')\n",
    "    plt.legend()\n",
    "    \n",
    "    # 显示整个图形\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
